# 实验配置
experiment:
  model: Qwen/Qwen2.5-3B-Instruct
  # model: unsloth/Qwen2.5-3B-Instruct-unsloth-bnb-4bit
  name: better_reward_3  # 实验名称，可通过命令行参数覆盖
  description: |

# GPU 参数
gpu:
  memory_utilization: 0.7  # 若 OOM，可降低此值
  visible_devices: -1

# 训练参数
training:
  grpo_num_generations: 6   # 若 OOM，可降低此值
  total_steps: 500
  save_steps: 50

# 随机种子
random_state: 1999

# LoRA 参数
lora:
  rank: 64  # 更大的秩 = 更智能，但更慢，建议选择 8, 16, 32, 64, 128

# 序列长度参数
sequence:
  max_prompt_length: 768
  max_completion_length: 2048

# 路径配置
paths:
  project_root: /root/proj/r1  # 项目根目录
  output_root: /root/lanyun-tmp/r1  # 项目输出目录

# 环境变量
environment:
  hf_hub_enable_hf_transfer: 0
  vllm_use_v1: 0

